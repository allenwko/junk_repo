{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from pandas_datareader import data as pddr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "def get_sp_tickers():\n",
    "    ''' Scrapes list of S&P 500 companies and ticker symbols from Wikipedia'''\n",
    "    \n",
    "    WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "    req = requests.get(WIKI_URL)\n",
    "    soup = BeautifulSoup(req.content, 'lxml')\n",
    "    table_classes = {\"class\": [\"sortable\", \"plainrowheaders\"]}\n",
    "    wikitables = soup.findAll(\"table\", table_classes)\n",
    "\n",
    "    rows = wikitables[0].findAll('tr')\n",
    "    headers = [i.text for i in rows[0].findAll('th')]\n",
    "    table_data = map(lambda x:[i.text for i in x.findAll('td')], rows[1:])\n",
    "    sp = pd.DataFrame(table_data, columns = headers)\n",
    "    sp['Ticker symbol'] = sp['Ticker symbol'].astype(str)\n",
    "    return sp\n",
    "\n",
    "sp_df = get_sp_tickers()\n",
    "\n",
    "def batch_data_pull(tickers, start_date, end_date, batch_size = 200):\n",
    "    '''Takes in a list of ticker symbols, and grabs all the Yahoo stock data between start and end dates'''\n",
    "    \n",
    "    assert len(tickers) > batch_size, 'Not a batch pull buddy'\n",
    "    batches = int(round(len(tickers) / batch_size))\n",
    "    ticker_batches = np.array_split(tickers, batches)\n",
    "    raw_data = []\n",
    "    data_source = 'yahoo'\n",
    "    \n",
    "    for ticker_batch in ticker_batches:\n",
    "        # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "        panel_data = pddr.DataReader(ticker_batch, data_source, start_date, end_date)\n",
    "        raw_data.append(panel_data)\n",
    "        data = pd.concat(raw_data, axis=2)\n",
    "    return data\n",
    "\n",
    "stock_data = batch_data_pull(sp_df['Ticker symbol'], '2017-06-01', '2017-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looking at effects of after hours trading\n",
    "# normal, mean centered on + 0.04% - almost no efect, long tailed both ways though\n",
    "ah_delta = (stock_data.loc['Open'] - stock_data['Close'].shift(-1)) / stock_data['Close'].shift(-1) * 100\n",
    "\n",
    "# when narrowing down population to after 5% drops, pretty skewed distribution - prices tend to drop a little bit\n",
    "# heavy tailed towards dropping a lot\n",
    "stacked_delta = ah_delta.stack()\n",
    "#stacked_delta.loc[high_stack.set_index(['Date', 'ticker']).index].hist(bins=20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
